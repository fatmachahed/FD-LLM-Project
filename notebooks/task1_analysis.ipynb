{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "148963bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET : IRIS\n",
      "============================================================\n",
      "Shape : (150, 5)\n",
      "Nombre de FDs : 4\n",
      "Taille moyenne du LHS : 3.0\n",
      "\n",
      "Fréquence des attributs (LHS) :\n",
      "  petal_length : 3\n",
      "  sepal_width : 3\n",
      "  sepal_length : 3\n",
      "  petal_width : 3\n",
      "\n",
      "Fréquence des attributs (RHS) :\n",
      "  class : 4\n",
      "\n",
      "Dépendances fonctionnelles :\n",
      "  petal_length, sepal_width, sepal_length -> class\n",
      "  petal_width, sepal_width, sepal_length -> class\n",
      "  petal_width, petal_length, sepal_length -> class\n",
      "  petal_width, petal_length, sepal_width -> class\n",
      "\n",
      "FDs triviales ou suspectes :\n",
      "  Aucune\n",
      "\n",
      "============================================================\n",
      "DATASET : ADULT\n",
      "============================================================\n",
      "Shape : (32561, 15)\n",
      "Nombre de FDs : 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# --- 3. Taille moyenne du LHS ---\u001b[39;00m\n\u001b[0;32m     82\u001b[0m lhs_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(lhs) \u001b[38;5;28;01mfor\u001b[39;00m lhs, _ \u001b[38;5;129;01min\u001b[39;00m fds]\n\u001b[1;32m---> 83\u001b[0m avg_lhs_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlhs_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlhs_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaille moyenne du LHS :\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(avg_lhs_size, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# --- 4. Fréquence des attributs ---\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# CONFIGURATION DES DATASETS\n",
    "# =========================\n",
    "DATASETS = {\n",
    "    \"iris\": {\n",
    "        \"data_file\": \"../data/iris/iris.data\",\n",
    "        \"fd_file\": \"../data/iris/iris_fds.txt\",\n",
    "        \"columns\": [\n",
    "            \"sepal_length\", \"sepal_width\",\n",
    "            \"petal_length\", \"petal_width\",\n",
    "            \"class\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"adult\": {\n",
    "        \"data_file\": \"../data/adult/adult.data\",\n",
    "        \"fd_file\": \"../data/adult/adult_fds.txt\",\n",
    "        \"columns\": [\n",
    "            \"age\",\n",
    "            \"workclass\",\n",
    "            \"fnlwgt\",\n",
    "            \"education\",\n",
    "            \"education_num\",\n",
    "            \"marital_status\",\n",
    "            \"occupation\",\n",
    "            \"relationship\",\n",
    "            \"race\",\n",
    "            \"sex\",\n",
    "            \"capital_gain\",\n",
    "            \"capital_loss\",\n",
    "            \"hours_per_week\",\n",
    "            \"native_country\",\n",
    "            \"income\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# FONCTION DE LECTURE DES FDs (TANE)\n",
    "# =========================\n",
    "def load_fds(fd_file, column_names):\n",
    "    fds = []\n",
    "    with open(fd_file, \"r\") as f:\n",
    "        in_results = False\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"# RESULTS\"):\n",
    "                in_results = True\n",
    "                continue\n",
    "            if in_results and \"->\" in line:\n",
    "                lhs, rhs = line.split(\"->\")\n",
    "                lhs_idx = [int(i) - 1 for i in lhs.split(\",\")]\n",
    "                rhs_idx = int(rhs) - 1\n",
    "                lhs_names = [column_names[i] for i in lhs_idx]\n",
    "                rhs_name = column_names[rhs_idx]\n",
    "                fds.append((lhs_names, rhs_name))\n",
    "    return fds\n",
    "\n",
    "# =========================\n",
    "# ANALYSE POUR CHAQUE DATASET\n",
    "# =========================\n",
    "for dataset_name, cfg in DATASETS.items():\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"DATASET : {dataset_name.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- 1. Charger le dataset ---\n",
    "    df = pd.read_csv(cfg[\"data_file\"], names=cfg[\"columns\"])\n",
    "    print(\"Shape :\", df.shape)\n",
    "\n",
    "    # --- 2. Charger les FDs ---\n",
    "    fds = load_fds(cfg[\"fd_file\"], cfg[\"columns\"])\n",
    "    print(\"Nombre de FDs :\", len(fds))\n",
    "\n",
    "    # --- 3. Taille moyenne du LHS ---\n",
    "    lhs_sizes = [len(lhs) for lhs, _ in fds]\n",
    "    avg_lhs_size = sum(lhs_sizes) / len(lhs_sizes)\n",
    "    print(\"Taille moyenne du LHS :\", round(avg_lhs_size, 2))\n",
    "\n",
    "    # --- 4. Fréquence des attributs ---\n",
    "    lhs_counter = Counter()\n",
    "    rhs_counter = Counter()\n",
    "\n",
    "    for lhs, rhs in fds:\n",
    "        lhs_counter.update(lhs)\n",
    "        rhs_counter.update([rhs])\n",
    "\n",
    "    print(\"\\nFréquence des attributs (LHS) :\")\n",
    "    for attr, count in lhs_counter.items():\n",
    "        print(f\"  {attr} : {count}\")\n",
    "\n",
    "    print(\"\\nFréquence des attributs (RHS) :\")\n",
    "    for attr, count in rhs_counter.items():\n",
    "        print(f\"  {attr} : {count}\")\n",
    "\n",
    "    # --- 5. Affichage des FDs ---\n",
    "    print(\"\\nDépendances fonctionnelles :\")\n",
    "    for lhs, rhs in fds:\n",
    "        print(f\"  {', '.join(lhs)} -> {rhs}\")\n",
    "\n",
    "    # --- 6. FDs triviales / suspectes ---\n",
    "    print(\"\\nFDs triviales ou suspectes :\")\n",
    "    found = False\n",
    "    for lhs, rhs in fds:\n",
    "        if len(lhs) == 1 and lhs[0].lower() in [\"id\", \"index\"]:\n",
    "            print(f\"  Triviale : {lhs} -> {rhs}\")\n",
    "            found = True\n",
    "        elif len(lhs) > 3:\n",
    "            print(f\"  LHS très grande : {lhs} -> {rhs}\")\n",
    "            found = True\n",
    "\n",
    "    if not found:\n",
    "        print(\"  Aucune\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e30d166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET : IRIS\n",
      "============================================================\n",
      "Colonnes : ['sepal_length_in_cm', 'sepal_width_in_cm', 'petal_length_in_cm', 'petal_width_in_cm', 'class']\n",
      "Shape : (150, 5)\n",
      "Nombre de FDs : 4\n",
      "Taille moyenne du LHS : 3.0\n",
      "\n",
      "Fréquence des attributs (LHS) :\n",
      "  petal_length_in_cm : 3\n",
      "  sepal_width_in_cm : 3\n",
      "  sepal_length_in_cm : 3\n",
      "  petal_width_in_cm : 3\n",
      "\n",
      "Fréquence des attributs (RHS) :\n",
      "  class : 4\n",
      "\n",
      "Dépendances fonctionnelles :\n",
      "  petal_length_in_cm, sepal_width_in_cm, sepal_length_in_cm -> class\n",
      "  petal_width_in_cm, sepal_width_in_cm, sepal_length_in_cm -> class\n",
      "  petal_width_in_cm, petal_length_in_cm, sepal_length_in_cm -> class\n",
      "  petal_width_in_cm, petal_length_in_cm, sepal_width_in_cm -> class\n",
      "\n",
      "FDs triviales ou suspectes :\n",
      "  Aucune\n",
      "\n",
      "============================================================\n",
      "DATASET : ADULT\n",
      "============================================================\n",
      "Colonnes : ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
      "Shape : (32561, 15)\n",
      "Nombre de FDs : 0\n",
      "Taille moyenne du LHS : N/A (aucune FD trouvée)\n",
      "\n",
      "Fréquence des attributs (LHS) :\n",
      "\n",
      "Fréquence des attributs (RHS) :\n",
      "\n",
      "Dépendances fonctionnelles :\n",
      "  Aucune FD trouvée\n",
      "\n",
      "FDs triviales ou suspectes :\n",
      "  Aucune\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# CONFIGURATION DES DATASETS\n",
    "# =========================\n",
    "DATASETS = {\n",
    "    \"iris\": {\n",
    "        \"data_file\": \"../data/iris/iris.data\",\n",
    "        \"fd_file\": \"../data/iris/iris_fds.txt\",\n",
    "        \"names_file\": \"../data/iris/iris.names\"\n",
    "    },\n",
    "\n",
    "    \"adult\": {\n",
    "        \"data_file\": \"../data/adult/adult.data\",\n",
    "        \"fd_file\": \"../data/adult/adult_fds.txt\",\n",
    "        # Noms de colonnes hardcodés pour Adult\n",
    "        \"columns\": [\n",
    "            \"age\",\n",
    "            \"workclass\",\n",
    "            \"fnlwgt\",\n",
    "            \"education\",\n",
    "            \"education_num\",\n",
    "            \"marital_status\",\n",
    "            \"occupation\",\n",
    "            \"relationship\",\n",
    "            \"race\",\n",
    "            \"sex\",\n",
    "            \"capital_gain\",\n",
    "            \"capital_loss\",\n",
    "            \"hours_per_week\",\n",
    "            \"native_country\",\n",
    "            \"income\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# EXTRACTION DES COLONNES POUR IRIS\n",
    "# =========================\n",
    "def extract_columns_from_names(names_file):\n",
    "    columns = []\n",
    "    in_attr_section = False\n",
    "    with open(names_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Début de la section Attribute Information\n",
    "            if \"Attribute Information\" in line or \"Attribute information\" in line:\n",
    "                in_attr_section = True\n",
    "                continue\n",
    "            if in_attr_section:\n",
    "                if line == \"\" or line.startswith(\"Summary Statistics\") or line.startswith(\"Missing\"):\n",
    "                    break\n",
    "                match = re.match(r\"^\\d+\\.\\s*([a-zA-Z0-9_\\- ]+)\", line)\n",
    "                if match:\n",
    "                    col = match.group(1)\n",
    "                    col = col.lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "                    columns.append(col)\n",
    "                if \">50K\" in line or \"<=50K\" in line:\n",
    "                    if \"income\" not in columns:\n",
    "                        columns.append(\"income\")\n",
    "    return columns\n",
    "\n",
    "# =========================\n",
    "# FONCTION DE LECTURE DES FDs (TANE)\n",
    "# =========================\n",
    "def load_fds(fd_file, column_names):\n",
    "    fds = []\n",
    "    if not Path(fd_file).exists():\n",
    "        return fds\n",
    "    with open(fd_file, \"r\") as f:\n",
    "        in_results = False\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"# RESULTS\"):\n",
    "                in_results = True\n",
    "                continue\n",
    "            if in_results and \"->\" in line:\n",
    "                lhs, rhs = line.split(\"->\")\n",
    "                lhs_idx = [int(i) - 1 for i in lhs.split(\",\")]\n",
    "                rhs_idx = int(rhs) - 1\n",
    "                lhs_names = [column_names[i] for i in lhs_idx]\n",
    "                rhs_name = column_names[rhs_idx]\n",
    "                fds.append((lhs_names, rhs_name))\n",
    "    return fds\n",
    "\n",
    "# =========================\n",
    "# ANALYSE POUR CHAQUE DATASET\n",
    "# =========================\n",
    "for dataset_name, cfg in DATASETS.items():\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"DATASET : {dataset_name.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- 1. Déterminer les colonnes ---\n",
    "    if dataset_name == \"iris\":\n",
    "        columns = extract_columns_from_names(cfg[\"names_file\"])\n",
    "    else:\n",
    "        columns = cfg[\"columns\"]\n",
    "\n",
    "    print(\"Colonnes :\", columns)\n",
    "\n",
    "    # --- 2. Charger le dataset ---\n",
    "    df = pd.read_csv(cfg[\"data_file\"], names=columns)\n",
    "    print(\"Shape :\", df.shape)\n",
    "\n",
    "    # --- 3. Charger les FDs ---\n",
    "    fds = load_fds(cfg[\"fd_file\"], columns)\n",
    "    print(\"Nombre de FDs :\", len(fds))\n",
    "\n",
    "    # --- 4. Taille moyenne du LHS ---\n",
    "    lhs_sizes = [len(lhs) for lhs, _ in fds]\n",
    "    if len(lhs_sizes) > 0:\n",
    "        avg_lhs_size = sum(lhs_sizes) / len(lhs_sizes)\n",
    "        print(\"Taille moyenne du LHS :\", round(avg_lhs_size, 2))\n",
    "    else:\n",
    "        print(\"Taille moyenne du LHS : N/A (aucune FD trouvée)\")\n",
    "\n",
    "    # --- 5. Fréquence des attributs ---\n",
    "    lhs_counter = Counter()\n",
    "    rhs_counter = Counter()\n",
    "    for lhs, rhs in fds:\n",
    "        lhs_counter.update(lhs)\n",
    "        rhs_counter.update([rhs])\n",
    "\n",
    "    print(\"\\nFréquence des attributs (LHS) :\")\n",
    "    for attr, count in lhs_counter.items():\n",
    "        print(f\"  {attr} : {count}\")\n",
    "\n",
    "    print(\"\\nFréquence des attributs (RHS) :\")\n",
    "    for attr, count in rhs_counter.items():\n",
    "        print(f\"  {attr} : {count}\")\n",
    "\n",
    "    # --- 6. Affichage des FDs ---\n",
    "    print(\"\\nDépendances fonctionnelles :\")\n",
    "    if fds:\n",
    "        for lhs, rhs in fds:\n",
    "            print(f\"  {', '.join(lhs)} -> {rhs}\")\n",
    "    else:\n",
    "        print(\"  Aucune FD trouvée\")\n",
    "\n",
    "    # --- 7. FDs triviales / suspectes ---\n",
    "    print(\"\\nFDs triviales ou suspectes :\")\n",
    "    found = False\n",
    "    for lhs, rhs in fds:\n",
    "        if len(lhs) == 1 and lhs[0].lower() in [\"id\", \"index\"]:\n",
    "            print(f\"  Triviale : {lhs} -> {rhs}\")\n",
    "            found = True\n",
    "        elif len(lhs) > 3:\n",
    "            print(f\"  LHS très grande : {lhs} -> {rhs}\")\n",
    "            found = True\n",
    "    if not found:\n",
    "        print(\"  Aucune\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
